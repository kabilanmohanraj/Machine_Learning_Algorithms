# -*- coding: utf-8 -*-
"""Income_Qualification_Data_Set.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12i8vChPg6NhDAl3mCM_5blqk4qsSImmC
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
# %inline matplotlib
import seaborn as sns

import warnings
warnings.filterwarnings('ignore')

"""### Reading the dataset"""

train_data = pd.read_csv('train.csv')
test_data = pd.read_csv('test.csv')
train_data.head()

"""### Basic exploration of the dataset"""

train_data.info()

train_data.shape

train_data['Target'].unique()

len(train_data['Id'].unique())

"""#### Since the target column has 4 distinct values, it is a classification problem with 4 categories"""

train_data['Target'].count()

train_data['v18q1'].unique()

"""### Dropping columns having more than 30% null values"""

np.ceil(train_data['Target'].count()*0.3)

train_data.dropna(axis = 1, thresh=np.ceil(train_data['Target'].count()*0.3), inplace = True)
train_data.shape

"""#### 3 columns were dropped"""

train_data.info()

for column in list(train_data.columns)[:-1]:
    print(column, train_data[column].count())

for column in list(train_data.columns)[:-1]:
    if(train_data[column].dtype in ['object']):
        print(column, train_data[column].count())
        print(column, train_data[column].unique())

len(train_data['idhogar'].unique())

"""#### As for the dataset, it has both numerical and categorical variables, but in number format with an exception of 5 columns(String datatype). Out of them 3 columns have been found to have inconsistencies. Because of these inconsistencies, the datatype of the whole column was changed. Replacing the inconsistent values can be done by using min and max of that particular column.

#### Why are we replacing instead of dropping - 'yes' could mean the maximum and 'no' could mean the min value from that column. These columns refer to education years of the male and female members of the family. The column description directs us to replace 'yes' by 1 amd 'no' by 0.
"""

for column in ['edjefa', 'edjefe']:
    train_data[column][train_data[column]=='yes'] = 1
    train_data[column][train_data[column]=='no'] = 0

for column in ['edjefa', 'edjefe']:
    test_data[column][test_data[column]=='yes'] = 1
    test_data[column][test_data[column]=='no'] = 0

train_data['dependency'][train_data['dependency']=='yes'] = (train_data['hogar_nin']+train_data['hogar_mayor'])/(train_data['hogar_total']-(train_data['hogar_nin']+train_data['hogar_mayor']))

train_data['dependency'][train_data['dependency']=='no'] = (train_data['hogar_nin']+train_data['hogar_mayor'])/(train_data['hogar_total']-(train_data['hogar_nin']+train_data['hogar_mayor']))

test_data['dependency'][test_data['dependency']=='yes'] = (test_data['hogar_nin']+test_data['hogar_mayor'])/(test_data['hogar_total']-(test_data['hogar_nin']+test_data['hogar_mayor']))

test_data['dependency'][test_data['dependency']=='no'] = (test_data['hogar_nin']+test_data['hogar_mayor'])/(test_data['hogar_total']-(test_data['hogar_nin']+test_data['hogar_mayor']))

"""#### The inconsistent values were replaced accordingly (from directions in the column description)"""

for column in ['edjefa', 'edjefe', 'dependency']:
    if(train_data[column].dtype in ['object']):
        print(column, train_data[column].unique())

train_data['meaneduc'].count()

train_data = train_data.dropna(inplace=False)

train_data.shape

"""### Whether the dataset is biased or not"""

plt.figure()
plt.hist(train_data['Target'])
plt.show()

"""### The above is a histogram of values of the target variable

#### As we can see, the data is biased towards the poverty level-4. Therefore we can expect a highly biased output as well. Suitable ways to tackle this could be sample boosting(generating duplicates in order to balance the data distribuiton)
"""

from scipy.stats import itemfreq

freq_target = itemfreq(train_data['Target'])
freq_target

"""### Proof of biasness of the data"""

pd.DataFrame(freq_target, columns=['value', 'frequency']).plot(kind='bar', x='value', y='frequency')

"""### Whether all members of the house have the same poverty level"""



"""### If there is a house without a family head"""

train_data['parentesco1'].unique()

freq_fam_head = itemfreq(train_data['parentesco1'])
freq_fam_head

"""#### From this we can infer that there are 6582 houses without a family head.

### Feature Engineering
"""

from sklearn.preprocessing import MinMaxScaler

for column in ['edjefa', 'edjefe', 'dependency']:
    train_data[column] = pd.to_numeric(train_data[column])

scaler = MinMaxScaler()

for column in list(train_data.columns)[:-1]:
    if(train_data[column].dtype not in ['object']):
        train_data[column] = scaler.fit_transform(train_data[[column]])
train_data.head()

from sklearn.preprocessing import LabelEncoder

encoder = LabelEncoder()
train_data['idhogar'] = encoder.fit_transform(train_data[['idhogar']])

from sklearn.decomposition import PCA

pca = PCA(n_components=5)
pca_data = pca.fit_transform(train_data.iloc[:, 1:-1], train_data.iloc[:, -1])
pca_data.shape

pca_data_test = pca.fit_transform(test_data.iloc[:, 1:-1], test_data.iloc[:, -1])
pca_data_test.shape

pca.explained_variance_ratio_

"""### Training the model"""

from sklearn.ensemble import RandomForestClassifier

random_forest = RandomForestClassifier()

random_forest.fit(pca_data, train_data.iloc[:, -1])

for column in list(train_data.columns)[:-1]:
    if(test_data[column].dtype not in ['object']):
        test_data[column] = scaler.fit_transform(test_data[[column]])
test_data.head()

test_data.dropna(axis = 1, thresh=np.ceil(train_data['Target'].count()*0.3), inplace = True)
test_data.shape

train_data.columns

train_data['rez_esc']

test_data.drop(columns=['v2a1', 'v18q1', 'rez_esc'], inplace=True)

test_data['idhogar'] = encoder.fit_transform(test_data[['idhogar']])

random_forest.score(pca_data_test, test_data.iloc[:, -1])

for column in list(test_data.columns):
    if(test_data[column].dtype not in ['object']):
        test_data[column].fillna(test_data[column].median(), inplace=True)

